{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Teach Old Dog New Tricks - Train Facial identification model to understand Facial Emotion](https://www.dlology.com/blog/teach-old-dog-new-tricks-train-facial-identification-model-to-understand-facial-emotion/)\n",
    "You can download the [fer2013](https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/data) dataset from Kaggle. Each picture is 48x48 pixel grayscale images of faces.\n",
    "\n",
    "Import packages,\n",
    "realize how we import keras from tensorflow \n",
    "\n",
    "`tensorflow.python.keras`\n",
    "\n",
    "This is new in tensorflow version 1.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hasee\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.4.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.keras import models\n",
    "from tensorflow.python.keras import layers\n",
    "from tensorflow.python.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "from PIL import Image\n",
    "import os\n",
    "import shutil\n",
    "from keras_vggface.vggface import VGGFace\n",
    "import cv2\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Keras model\n",
    "We are leveraging the pre-trained VGG-Face2 model's convolution layers. aka the \"convolutional base\" of the model. Then we add our own classifier fully connected layers to do emotion classification. \n",
    "\n",
    "Note that since we don't want to touch the parameters pre-trained in the \"convolutional base\", so we set them as not trainable. Want to go deeper how this model works? Check out this great [jupyter notebook](https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/5.3-using-a-pretrained-convnet.ipynb) by the creator of Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3),\n",
    "                                pooling='avg')  # pooling: None, avg or max\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(7, activation='softmax'))\n",
    "conv_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vggface_resnet50 (Model)     (None, 2048)              23561152  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               524544    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 1799      \n",
      "=================================================================\n",
      "Total params: 24,087,495\n",
      "Trainable params: 4,988,935\n",
      "Non-trainable params: 19,098,560\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set 'activation_46' and following layers trainable\n",
    "conv_base.trainable = True\n",
    "\n",
    "set_trainable = False\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name == 'activation_46':\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation_46\n",
      "conv5_3_1x1_reduce\n",
      "conv5_3_1x1_reduce/bn\n",
      "activation_47\n",
      "conv5_3_3x3\n",
      "conv5_3_3x3/bn\n",
      "activation_48\n",
      "conv5_3_1x1_increase\n",
      "conv5_3_1x1_increase/bn\n",
      "add_16\n",
      "activation_49\n",
      "avg_pool\n",
      "global_average_pooling2d_1\n"
     ]
    }
   ],
   "source": [
    "for layer in conv_base.layers:\n",
    "    if layer.trainable:\n",
    "        print(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 224, 224, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv1/7x7_s2 (Conv2D)            (None, 112, 112, 64)  9408        input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv1/7x7_s2/bn (BatchNormalizat (None, 112, 112, 64)  256         conv1/7x7_s2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 112, 112, 64)  0           conv1/7x7_s2/bn[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, 55, 55, 64)    0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2_1_1x1_reduce (Conv2D)      (None, 55, 55, 64)    4096        max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2_1_1x1_reduce/bn (BatchNorm (None, 55, 55, 64)    256         conv2_1_1x1_reduce[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 55, 55, 64)    0           conv2_1_1x1_reduce/bn[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2_1_3x3 (Conv2D)             (None, 55, 55, 64)    36864       activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2_1_3x3/bn (BatchNormalizati (None, 55, 55, 64)    256         conv2_1_3x3[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 55, 55, 64)    0           conv2_1_3x3/bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2_1_1x1_increase (Conv2D)    (None, 55, 55, 256)   16384       activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2_1_1x1_proj (Conv2D)        (None, 55, 55, 256)   16384       max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2_1_1x1_increase/bn (BatchNo (None, 55, 55, 256)   1024        conv2_1_1x1_increase[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv2_1_1x1_proj/bn (BatchNormal (None, 55, 55, 256)   1024        conv2_1_1x1_proj[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "add_1 (Add)                      (None, 55, 55, 256)   0           conv2_1_1x1_increase/bn[0][0]    \n",
      "                                                                   conv2_1_1x1_proj/bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 55, 55, 256)   0           add_1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv2_2_1x1_reduce (Conv2D)      (None, 55, 55, 64)    16384       activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2_2_1x1_reduce/bn (BatchNorm (None, 55, 55, 64)    256         conv2_2_1x1_reduce[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 55, 55, 64)    0           conv2_2_1x1_reduce/bn[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2_2_3x3 (Conv2D)             (None, 55, 55, 64)    36864       activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2_2_3x3/bn (BatchNormalizati (None, 55, 55, 64)    256         conv2_2_3x3[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 55, 55, 64)    0           conv2_2_3x3/bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2_2_1x1_increase (Conv2D)    (None, 55, 55, 256)   16384       activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2_2_1x1_increase/bn (BatchNo (None, 55, 55, 256)   1024        conv2_2_1x1_increase[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "add_2 (Add)                      (None, 55, 55, 256)   0           conv2_2_1x1_increase/bn[0][0]    \n",
      "                                                                   activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 55, 55, 256)   0           add_2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv2_3_1x1_reduce (Conv2D)      (None, 55, 55, 64)    16384       activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2_3_1x1_reduce/bn (BatchNorm (None, 55, 55, 64)    256         conv2_3_1x1_reduce[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 55, 55, 64)    0           conv2_3_1x1_reduce/bn[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2_3_3x3 (Conv2D)             (None, 55, 55, 64)    36864       activation_8[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2_3_3x3/bn (BatchNormalizati (None, 55, 55, 64)    256         conv2_3_3x3[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)        (None, 55, 55, 64)    0           conv2_3_3x3/bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2_3_1x1_increase (Conv2D)    (None, 55, 55, 256)   16384       activation_9[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2_3_1x1_increase/bn (BatchNo (None, 55, 55, 256)   1024        conv2_3_1x1_increase[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "add_3 (Add)                      (None, 55, 55, 256)   0           conv2_3_1x1_increase/bn[0][0]    \n",
      "                                                                   activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_10 (Activation)       (None, 55, 55, 256)   0           add_3[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv3_1_1x1_reduce (Conv2D)      (None, 28, 28, 128)   32768       activation_10[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv3_1_1x1_reduce/bn (BatchNorm (None, 28, 28, 128)   512         conv3_1_1x1_reduce[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "activation_11 (Activation)       (None, 28, 28, 128)   0           conv3_1_1x1_reduce/bn[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv3_1_3x3 (Conv2D)             (None, 28, 28, 128)   147456      activation_11[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv3_1_3x3/bn (BatchNormalizati (None, 28, 28, 128)   512         conv3_1_3x3[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "activation_12 (Activation)       (None, 28, 28, 128)   0           conv3_1_3x3/bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv3_1_1x1_increase (Conv2D)    (None, 28, 28, 512)   65536       activation_12[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv3_1_1x1_proj (Conv2D)        (None, 28, 28, 512)   131072      activation_10[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv3_1_1x1_increase/bn (BatchNo (None, 28, 28, 512)   2048        conv3_1_1x1_increase[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv3_1_1x1_proj/bn (BatchNormal (None, 28, 28, 512)   2048        conv3_1_1x1_proj[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "add_4 (Add)                      (None, 28, 28, 512)   0           conv3_1_1x1_increase/bn[0][0]    \n",
      "                                                                   conv3_1_1x1_proj/bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "activation_13 (Activation)       (None, 28, 28, 512)   0           add_4[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv3_2_1x1_reduce (Conv2D)      (None, 28, 28, 128)   65536       activation_13[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv3_2_1x1_reduce/bn (BatchNorm (None, 28, 28, 128)   512         conv3_2_1x1_reduce[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "activation_14 (Activation)       (None, 28, 28, 128)   0           conv3_2_1x1_reduce/bn[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv3_2_3x3 (Conv2D)             (None, 28, 28, 128)   147456      activation_14[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv3_2_3x3/bn (BatchNormalizati (None, 28, 28, 128)   512         conv3_2_3x3[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "activation_15 (Activation)       (None, 28, 28, 128)   0           conv3_2_3x3/bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv3_2_1x1_increase (Conv2D)    (None, 28, 28, 512)   65536       activation_15[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv3_2_1x1_increase/bn (BatchNo (None, 28, 28, 512)   2048        conv3_2_1x1_increase[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "add_5 (Add)                      (None, 28, 28, 512)   0           conv3_2_1x1_increase/bn[0][0]    \n",
      "                                                                   activation_13[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_16 (Activation)       (None, 28, 28, 512)   0           add_5[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv3_3_1x1_reduce (Conv2D)      (None, 28, 28, 128)   65536       activation_16[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv3_3_1x1_reduce/bn (BatchNorm (None, 28, 28, 128)   512         conv3_3_1x1_reduce[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "activation_17 (Activation)       (None, 28, 28, 128)   0           conv3_3_1x1_reduce/bn[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv3_3_3x3 (Conv2D)             (None, 28, 28, 128)   147456      activation_17[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv3_3_3x3/bn (BatchNormalizati (None, 28, 28, 128)   512         conv3_3_3x3[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "activation_18 (Activation)       (None, 28, 28, 128)   0           conv3_3_3x3/bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv3_3_1x1_increase (Conv2D)    (None, 28, 28, 512)   65536       activation_18[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv3_3_1x1_increase/bn (BatchNo (None, 28, 28, 512)   2048        conv3_3_1x1_increase[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "add_6 (Add)                      (None, 28, 28, 512)   0           conv3_3_1x1_increase/bn[0][0]    \n",
      "                                                                   activation_16[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_19 (Activation)       (None, 28, 28, 512)   0           add_6[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv3_4_1x1_reduce (Conv2D)      (None, 28, 28, 128)   65536       activation_19[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv3_4_1x1_reduce/bn (BatchNorm (None, 28, 28, 128)   512         conv3_4_1x1_reduce[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "activation_20 (Activation)       (None, 28, 28, 128)   0           conv3_4_1x1_reduce/bn[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv3_4_3x3 (Conv2D)             (None, 28, 28, 128)   147456      activation_20[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv3_4_3x3/bn (BatchNormalizati (None, 28, 28, 128)   512         conv3_4_3x3[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "activation_21 (Activation)       (None, 28, 28, 128)   0           conv3_4_3x3/bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv3_4_1x1_increase (Conv2D)    (None, 28, 28, 512)   65536       activation_21[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv3_4_1x1_increase/bn (BatchNo (None, 28, 28, 512)   2048        conv3_4_1x1_increase[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "add_7 (Add)                      (None, 28, 28, 512)   0           conv3_4_1x1_increase/bn[0][0]    \n",
      "                                                                   activation_19[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_22 (Activation)       (None, 28, 28, 512)   0           add_7[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv4_1_1x1_reduce (Conv2D)      (None, 14, 14, 256)   131072      activation_22[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv4_1_1x1_reduce/bn (BatchNorm (None, 14, 14, 256)   1024        conv4_1_1x1_reduce[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "activation_23 (Activation)       (None, 14, 14, 256)   0           conv4_1_1x1_reduce/bn[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv4_1_3x3 (Conv2D)             (None, 14, 14, 256)   589824      activation_23[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv4_1_3x3/bn (BatchNormalizati (None, 14, 14, 256)   1024        conv4_1_3x3[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "activation_24 (Activation)       (None, 14, 14, 256)   0           conv4_1_3x3/bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv4_1_1x1_increase (Conv2D)    (None, 14, 14, 1024)  262144      activation_24[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv4_1_1x1_proj (Conv2D)        (None, 14, 14, 1024)  524288      activation_22[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv4_1_1x1_increase/bn (BatchNo (None, 14, 14, 1024)  4096        conv4_1_1x1_increase[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv4_1_1x1_proj/bn (BatchNormal (None, 14, 14, 1024)  4096        conv4_1_1x1_proj[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "add_8 (Add)                      (None, 14, 14, 1024)  0           conv4_1_1x1_increase/bn[0][0]    \n",
      "                                                                   conv4_1_1x1_proj/bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "activation_25 (Activation)       (None, 14, 14, 1024)  0           add_8[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv4_2_1x1_reduce (Conv2D)      (None, 14, 14, 256)   262144      activation_25[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv4_2_1x1_reduce/bn (BatchNorm (None, 14, 14, 256)   1024        conv4_2_1x1_reduce[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "activation_26 (Activation)       (None, 14, 14, 256)   0           conv4_2_1x1_reduce/bn[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv4_2_3x3 (Conv2D)             (None, 14, 14, 256)   589824      activation_26[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv4_2_3x3/bn (BatchNormalizati (None, 14, 14, 256)   1024        conv4_2_3x3[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "activation_27 (Activation)       (None, 14, 14, 256)   0           conv4_2_3x3/bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv4_2_1x1_increase (Conv2D)    (None, 14, 14, 1024)  262144      activation_27[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv4_2_1x1_increase/bn (BatchNo (None, 14, 14, 1024)  4096        conv4_2_1x1_increase[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "add_9 (Add)                      (None, 14, 14, 1024)  0           conv4_2_1x1_increase/bn[0][0]    \n",
      "                                                                   activation_25[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_28 (Activation)       (None, 14, 14, 1024)  0           add_9[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv4_3_1x1_reduce (Conv2D)      (None, 14, 14, 256)   262144      activation_28[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv4_3_1x1_reduce/bn (BatchNorm (None, 14, 14, 256)   1024        conv4_3_1x1_reduce[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "activation_29 (Activation)       (None, 14, 14, 256)   0           conv4_3_1x1_reduce/bn[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv4_3_3x3 (Conv2D)             (None, 14, 14, 256)   589824      activation_29[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv4_3_3x3/bn (BatchNormalizati (None, 14, 14, 256)   1024        conv4_3_3x3[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "activation_30 (Activation)       (None, 14, 14, 256)   0           conv4_3_3x3/bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv4_3_1x1_increase (Conv2D)    (None, 14, 14, 1024)  262144      activation_30[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv4_3_1x1_increase/bn (BatchNo (None, 14, 14, 1024)  4096        conv4_3_1x1_increase[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "add_10 (Add)                     (None, 14, 14, 1024)  0           conv4_3_1x1_increase/bn[0][0]    \n",
      "                                                                   activation_28[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_31 (Activation)       (None, 14, 14, 1024)  0           add_10[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv4_4_1x1_reduce (Conv2D)      (None, 14, 14, 256)   262144      activation_31[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv4_4_1x1_reduce/bn (BatchNorm (None, 14, 14, 256)   1024        conv4_4_1x1_reduce[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "activation_32 (Activation)       (None, 14, 14, 256)   0           conv4_4_1x1_reduce/bn[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv4_4_3x3 (Conv2D)             (None, 14, 14, 256)   589824      activation_32[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv4_4_3x3/bn (BatchNormalizati (None, 14, 14, 256)   1024        conv4_4_3x3[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "activation_33 (Activation)       (None, 14, 14, 256)   0           conv4_4_3x3/bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv4_4_1x1_increase (Conv2D)    (None, 14, 14, 1024)  262144      activation_33[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv4_4_1x1_increase/bn (BatchNo (None, 14, 14, 1024)  4096        conv4_4_1x1_increase[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "add_11 (Add)                     (None, 14, 14, 1024)  0           conv4_4_1x1_increase/bn[0][0]    \n",
      "                                                                   activation_31[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_34 (Activation)       (None, 14, 14, 1024)  0           add_11[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv4_5_1x1_reduce (Conv2D)      (None, 14, 14, 256)   262144      activation_34[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv4_5_1x1_reduce/bn (BatchNorm (None, 14, 14, 256)   1024        conv4_5_1x1_reduce[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "activation_35 (Activation)       (None, 14, 14, 256)   0           conv4_5_1x1_reduce/bn[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv4_5_3x3 (Conv2D)             (None, 14, 14, 256)   589824      activation_35[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv4_5_3x3/bn (BatchNormalizati (None, 14, 14, 256)   1024        conv4_5_3x3[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "activation_36 (Activation)       (None, 14, 14, 256)   0           conv4_5_3x3/bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv4_5_1x1_increase (Conv2D)    (None, 14, 14, 1024)  262144      activation_36[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv4_5_1x1_increase/bn (BatchNo (None, 14, 14, 1024)  4096        conv4_5_1x1_increase[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "add_12 (Add)                     (None, 14, 14, 1024)  0           conv4_5_1x1_increase/bn[0][0]    \n",
      "                                                                   activation_34[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_37 (Activation)       (None, 14, 14, 1024)  0           add_12[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv4_6_1x1_reduce (Conv2D)      (None, 14, 14, 256)   262144      activation_37[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv4_6_1x1_reduce/bn (BatchNorm (None, 14, 14, 256)   1024        conv4_6_1x1_reduce[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "activation_38 (Activation)       (None, 14, 14, 256)   0           conv4_6_1x1_reduce/bn[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv4_6_3x3 (Conv2D)             (None, 14, 14, 256)   589824      activation_38[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv4_6_3x3/bn (BatchNormalizati (None, 14, 14, 256)   1024        conv4_6_3x3[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "activation_39 (Activation)       (None, 14, 14, 256)   0           conv4_6_3x3/bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv4_6_1x1_increase (Conv2D)    (None, 14, 14, 1024)  262144      activation_39[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv4_6_1x1_increase/bn (BatchNo (None, 14, 14, 1024)  4096        conv4_6_1x1_increase[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "add_13 (Add)                     (None, 14, 14, 1024)  0           conv4_6_1x1_increase/bn[0][0]    \n",
      "                                                                   activation_37[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_40 (Activation)       (None, 14, 14, 1024)  0           add_13[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv5_1_1x1_reduce (Conv2D)      (None, 7, 7, 512)     524288      activation_40[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv5_1_1x1_reduce/bn (BatchNorm (None, 7, 7, 512)     2048        conv5_1_1x1_reduce[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "activation_41 (Activation)       (None, 7, 7, 512)     0           conv5_1_1x1_reduce/bn[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv5_1_3x3 (Conv2D)             (None, 7, 7, 512)     2359296     activation_41[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv5_1_3x3/bn (BatchNormalizati (None, 7, 7, 512)     2048        conv5_1_3x3[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "activation_42 (Activation)       (None, 7, 7, 512)     0           conv5_1_3x3/bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv5_1_1x1_increase (Conv2D)    (None, 7, 7, 2048)    1048576     activation_42[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv5_1_1x1_proj (Conv2D)        (None, 7, 7, 2048)    2097152     activation_40[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv5_1_1x1_increase/bn (BatchNo (None, 7, 7, 2048)    8192        conv5_1_1x1_increase[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "conv5_1_1x1_proj/bn (BatchNormal (None, 7, 7, 2048)    8192        conv5_1_1x1_proj[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "add_14 (Add)                     (None, 7, 7, 2048)    0           conv5_1_1x1_increase/bn[0][0]    \n",
      "                                                                   conv5_1_1x1_proj/bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "activation_43 (Activation)       (None, 7, 7, 2048)    0           add_14[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv5_2_1x1_reduce (Conv2D)      (None, 7, 7, 512)     1048576     activation_43[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv5_2_1x1_reduce/bn (BatchNorm (None, 7, 7, 512)     2048        conv5_2_1x1_reduce[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "activation_44 (Activation)       (None, 7, 7, 512)     0           conv5_2_1x1_reduce/bn[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv5_2_3x3 (Conv2D)             (None, 7, 7, 512)     2359296     activation_44[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv5_2_3x3/bn (BatchNormalizati (None, 7, 7, 512)     2048        conv5_2_3x3[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "activation_45 (Activation)       (None, 7, 7, 512)     0           conv5_2_3x3/bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv5_2_1x1_increase (Conv2D)    (None, 7, 7, 2048)    1048576     activation_45[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv5_2_1x1_increase/bn (BatchNo (None, 7, 7, 2048)    8192        conv5_2_1x1_increase[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "add_15 (Add)                     (None, 7, 7, 2048)    0           conv5_2_1x1_increase/bn[0][0]    \n",
      "                                                                   activation_43[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_46 (Activation)       (None, 7, 7, 2048)    0           add_15[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv5_3_1x1_reduce (Conv2D)      (None, 7, 7, 512)     1048576     activation_46[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv5_3_1x1_reduce/bn (BatchNorm (None, 7, 7, 512)     2048        conv5_3_1x1_reduce[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "activation_47 (Activation)       (None, 7, 7, 512)     0           conv5_3_1x1_reduce/bn[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv5_3_3x3 (Conv2D)             (None, 7, 7, 512)     2359296     activation_47[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv5_3_3x3/bn (BatchNormalizati (None, 7, 7, 512)     2048        conv5_3_3x3[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "activation_48 (Activation)       (None, 7, 7, 512)     0           conv5_3_3x3/bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv5_3_1x1_increase (Conv2D)    (None, 7, 7, 2048)    1048576     activation_48[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv5_3_1x1_increase/bn (BatchNo (None, 7, 7, 2048)    8192        conv5_3_1x1_increase[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "add_16 (Add)                     (None, 7, 7, 2048)    0           conv5_3_1x1_increase/bn[0][0]    \n",
      "                                                                   activation_46[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_49 (Activation)       (None, 7, 7, 2048)    0           add_16[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "avg_pool (AveragePooling2D)      (None, 1, 1, 2048)    0           activation_49[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glob (None, 2048)          0           avg_pool[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 23,561,152\n",
      "Trainable params: 4,462,592\n",
      "Non-trainable params: 19,098,560\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras model to TF estimator\n",
    "`model_dir` will be our location to store trained tensorflow models. Training progress can be viewed by TensorBoard.\n",
    "\n",
    "I found that I have to specify the full path, otherwise, Tensorflow will complain about it later during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_dir:  E:\\SW_WS\\Python_SW\\face_classification\\src\\models\\emotion_vgg16\n",
      "INFO:tensorflow:Using the Keras model from memory.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_num_worker_replicas': 1, '_num_ps_replicas': 0, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_session_config': None, '_save_checkpoints_secs': 600, '_task_id': 0, '_task_type': 'worker', '_keep_checkpoint_max': 5, '_model_dir': 'E:\\\\SW_WS\\\\Python_SW\\\\face_classification\\\\src\\\\models\\\\emotion_vgg16', '_master': '', '_tf_random_seed': None, '_save_checkpoints_steps': None, '_log_step_count_steps': 100, '_save_summary_steps': 100, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000002B4DC416F98>}\n"
     ]
    }
   ],
   "source": [
    "model_dir = os.path.join(os.getcwd(), \"models//emotion_vgg16\").replace(\"//\", \"\\\\\")\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "print(\"model_dir: \",model_dir)\n",
    "est_emotion = tf.keras.estimator.model_to_estimator(keras_model=model,\n",
    "                                                    model_dir=model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input_name is the model's input layer name, we will need it later when building Input function for your estimator. More on that in Input function section below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'input_1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input layer name\n",
    "input_name = model.input_names[0]\n",
    "input_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"./datasets/fer2013/fer2013.csv\"\n",
    "data = pd.read_csv(dataset_path)\n",
    "pixels = data['pixels'].tolist()\n",
    "src_size = (48, 48)\n",
    "\n",
    "faces = []\n",
    "for pixel_sequence in pixels:\n",
    "    face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
    "    face = np.asarray(face).reshape(src_size)\n",
    "    faces.append(face.astype('float32'))\n",
    "faces = np.asarray(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    8989\n",
       "6    6198\n",
       "4    6077\n",
       "2    5121\n",
       "0    4953\n",
       "5    4002\n",
       "1     547\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "# (0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral)\n",
    "emotions = pd.get_dummies(data['emotion']).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(x, y, validation_split=.2):\n",
    "    num_samples = len(x)\n",
    "    num_train_samples = int((1 - validation_split)*num_samples)\n",
    "    train_x = x[:num_train_samples]\n",
    "    train_y = y[:num_train_samples]\n",
    "    val_x = x[num_train_samples:]\n",
    "    val_y = y[num_train_samples:]\n",
    "    train_data = (train_x, train_y)\n",
    "    val_data = (val_x, val_y)\n",
    "    return train_data, val_data\n",
    "\n",
    "train_data, val_data = split_data(faces, emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = './data/emotion'\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "path_tfrecords_train = os.path.join(base_dir, \"train.tfrecords\")\n",
    "path_tfrecords_test = os.path.join(base_dir, \"test.tfrecords\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper-function for printing the conversion progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_progress(count, total):\n",
    "    # Percentage completion.\n",
    "    pct_complete = float(count) / total\n",
    "\n",
    "    # Status-message.\n",
    "    # Note the \\r which means the line should overwrite itself.\n",
    "    msg = \"\\r- Progress: {0:.1%}\".format(pct_complete)\n",
    "\n",
    "    # Print it.\n",
    "    sys.stdout.write(msg)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper-function for wrapping an integer so it can be saved to the TFRecord file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_int64(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper-function for wrapping a list of integer so it can be saved to the TFRecord file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_int64_list(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper-function for wrapping raw bytes so they can be saved to the TFRecord file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_bytes(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for reading images from disk and writing them along with the class-labels to a TFRecord file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(image_arrays, labels, out_path, size=(224,224)):\n",
    "    # Args:\n",
    "    # image_paths   List of numpy image arrays.\n",
    "    # labels        Class-labels for the images.\n",
    "    # out_path      File-path for the TFRecords output file.    \n",
    "    print(\"Converting: \" + out_path)\n",
    "    # Number of images. Used when printing the progress.\n",
    "    num_images = len(image_arrays)    \n",
    "    # Open a TFRecordWriter for the output-file.\n",
    "    with tf.python_io.TFRecordWriter(out_path) as writer:\n",
    "        # Iterate over all the image-paths and class-labels.\n",
    "        for i, (img, label) in enumerate(zip(image_arrays, labels)):\n",
    "            # Print the percentage-progress.\n",
    "            print_progress(count=i, total=num_images-1)\n",
    "            # resize the image array to desired size\n",
    "            img = cv2.resize(img.astype('uint8'), size)    \n",
    "            # Turn gray to color.\n",
    "            img = cv2.cvtColor(img,cv2.COLOR_GRAY2RGB)\n",
    "            # Convert the image to raw bytes.\n",
    "            img_bytes = img.tostring()\n",
    "            # Create a dict with the data we want to save in the\n",
    "            # TFRecords file. You can add more relevant data here.\n",
    "            data = \\\n",
    "                {\n",
    "                    'image': wrap_bytes(img_bytes),\n",
    "                    'label': wrap_int64_list(label)\n",
    "                }\n",
    "            # Wrap the data as TensorFlow Features.\n",
    "            feature = tf.train.Features(feature=data)\n",
    "            # Wrap again as a TensorFlow Example.\n",
    "            example = tf.train.Example(features=feature)\n",
    "            # Serialize the data.\n",
    "            serialized = example.SerializeToString()        \n",
    "            # Write the serialized data to the TFRecords file.\n",
    "            writer.write(serialized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Converting: ./data/emotion\\train.tfrecords\n",
      "A\n",
      "- Progress: 0.0%ERROR! Session/line number was not unique in database. History logging moved to new session 929\n",
      "- Progress: 100.0%Converting: ./data/emotion\\test.tfrecords\n",
      "A\n",
      "- Progress: 100.0%"
     ]
    }
   ],
   "source": [
    "convert(image_arrays=train_data[0],\n",
    "        labels=train_data[1],\n",
    "        out_path=path_tfrecords_train)\n",
    "convert(image_arrays=val_data[0],\n",
    "        labels=val_data[1],\n",
    "        out_path=path_tfrecords_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input function\n",
    "When we train our model, we'll need a function that reads the input image and labels and returns the image data and labels. Estimators require that you create a function of the following format:\n",
    "````\n",
    "def input_fn():\n",
    "    ...<code>...\n",
    "    return ({ 'input_1':[ImagesValues]},\n",
    "            [ImageTypeLogit])\n",
    "```\n",
    "The return value must be a two-element tuple organized as follows: :\n",
    "\n",
    "- The first element must be a dictionary in which each input feature is a key, and then a list of values for the training batch.\n",
    "- The second element is a list of labels for the training batch.\n",
    "### Arguments\n",
    "- **filenames**, TF-record file name\n",
    "- **perform_shuffle=False**, Useful when training, reads batch_size records, then shuffles (randomizes) their order.\n",
    "- **repeat_count=1**, Useful when training, repeat the input data several times for each epoch\n",
    "- **batch_size=1**, Reads batch_size records at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imgs_input_fn(filenames, perform_shuffle=False, \n",
    "                  repeat_count=1, batch_size=1):\n",
    "    def _parse_function(serialized):\n",
    "        features = \\\n",
    "        {\n",
    "            'image': tf.FixedLenFeature([], tf.string),\n",
    "            'label': tf.FixedLenFeature([7], tf.int64)\n",
    "        }\n",
    "        # Parse the serialized data so we get a dict with our data.\n",
    "        parsed_example = tf.parse_single_example(serialized=serialized,\n",
    "                                                 features=features)\n",
    "        # Get the image as raw bytes.\n",
    "        image_shape = tf.stack([224, 224, 3])\n",
    "        image_raw = parsed_example['image']\n",
    "        label = tf.cast(parsed_example['label'], tf.float32)\n",
    "        # Decode the raw bytes so it becomes a tensor with type.\n",
    "        image = tf.decode_raw(image_raw, tf.uint8)\n",
    "        image = tf.cast(image, tf.float32)\n",
    "        image = tf.reshape(image, image_shape)\n",
    "        image = tf.subtract(image, 116.779) # Zero-center by mean pixel\n",
    "        image = tf.reverse(image, axis=[2]) # 'RGB'->'BGR'\n",
    "        d = dict(zip([input_name], [image])), label\n",
    "        return d\n",
    "    \n",
    "    dataset = tf.data.TFRecordDataset(filenames=filenames)\n",
    "    # Parse the serialized data in the TFRecords files.\n",
    "    # This returns TensorFlow tensors for the image and labels.\n",
    "    dataset = dataset.map(_parse_function)\n",
    "    if perform_shuffle:\n",
    "        # Randomizes input using a window of 256 elements (read into memory)\n",
    "        dataset = dataset.shuffle(buffer_size=256)\n",
    "    dataset = dataset.repeat(repeat_count)  # Repeats dataset this # times\n",
    "    dataset = dataset.batch(batch_size)  # Batch size to use\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    batch_features, batch_labels = iterator.get_next()\n",
    "    return batch_features, batch_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the input function output\n",
    "Looks like color channels 'RGB' has changed to 'BGR' and shape resized to (224, 224) correctly for our model. That is the input format the VGGFace's \"convolutional base\" is expecting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch input shape: (20, 224, 224, 3)\n",
      "batch output shape: (20, 7)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOAAAADgCAIAAACVT/22AABkM0lEQVR4nM29yZYkOY4ECFLN94jI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\ngg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=224x224 at 0x203499CF6A0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_batch = imgs_input_fn(path_tfrecords_test, perform_shuffle=True, batch_size=20)\n",
    "with tf.Session() as sess:\n",
    "    first_batch = sess.run(next_batch)\n",
    "x_d = first_batch[0]['input_1']\n",
    "y_d = first_batch[1]\n",
    "print(\"batch input shape: {}\".format(x_d.shape))\n",
    "print(\"batch output shape: {}\".format(y_d.shape))\n",
    "img = image.array_to_img(x_d[8])\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 53.221    ,  53.221    ,  53.221    ],\n",
       "        [ 53.221    ,  53.221    ,  53.221    ],\n",
       "        [ 53.221    ,  53.221    ,  53.221    ],\n",
       "        ...,\n",
       "        [  3.2210007,   3.2210007,   3.2210007],\n",
       "        [  2.2210007,   2.2210007,   2.2210007],\n",
       "        [  2.2210007,   2.2210007,   2.2210007]],\n",
       "\n",
       "       [[ 53.221    ,  53.221    ,  53.221    ],\n",
       "        [ 53.221    ,  53.221    ,  53.221    ],\n",
       "        [ 53.221    ,  53.221    ,  53.221    ],\n",
       "        ...,\n",
       "        [  3.2210007,   3.2210007,   3.2210007],\n",
       "        [  2.2210007,   2.2210007,   2.2210007],\n",
       "        [  2.2210007,   2.2210007,   2.2210007]],\n",
       "\n",
       "       [[ 53.221    ,  53.221    ,  53.221    ],\n",
       "        [ 53.221    ,  53.221    ,  53.221    ],\n",
       "        [ 53.221    ,  53.221    ,  53.221    ],\n",
       "        ...,\n",
       "        [  3.2210007,   3.2210007,   3.2210007],\n",
       "        [  2.2210007,   2.2210007,   2.2210007],\n",
       "        [  2.2210007,   2.2210007,   2.2210007]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 79.221    ,  79.221    ,  79.221    ],\n",
       "        [ 79.221    ,  79.221    ,  79.221    ],\n",
       "        [ 79.221    ,  79.221    ,  79.221    ],\n",
       "        ...,\n",
       "        [-27.779    , -27.779    , -27.779    ],\n",
       "        [-27.779    , -27.779    , -27.779    ],\n",
       "        [-27.779    , -27.779    , -27.779    ]],\n",
       "\n",
       "       [[ 78.221    ,  78.221    ,  78.221    ],\n",
       "        [ 78.221    ,  78.221    ,  78.221    ],\n",
       "        [ 79.221    ,  79.221    ,  79.221    ],\n",
       "        ...,\n",
       "        [-27.779    , -27.779    , -27.779    ],\n",
       "        [-27.779    , -27.779    , -27.779    ],\n",
       "        [-27.779    , -27.779    , -27.779    ]],\n",
       "\n",
       "       [[ 78.221    ,  78.221    ,  78.221    ],\n",
       "        [ 78.221    ,  78.221    ,  78.221    ],\n",
       "        [ 79.221    ,  79.221    ,  79.221    ],\n",
       "        ...,\n",
       "        [-27.779    , -27.779    , -27.779    ],\n",
       "        [-27.779    , -27.779    , -27.779    ],\n",
       "        [-27.779    , -27.779    , -27.779    ]]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_d[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.estimator.train_and_evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow release 1.4 also introduces the utility function **tf.estimator.train_and_evaluate**, which simplifies training, evaluation, and exporting Estimator models. This function enables distributed execution for training and evaluation, while still supporting local execution.\n",
    "\n",
    "Notice that the train was build on previous training result when we call the `est_emotion.train()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 600 secs (eval_spec.throttle_secs) or training is finished.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from E:\\SW_WS\\Python_SW\\face_classification\\src\\models\\emotion_vgg16/\n",
      "INFO:tensorflow:Saving checkpoints for 1 into E:\\SW_WS\\Python_SW\\face_classification\\src\\models\\emotion_vgg16\\model.ckpt.\n",
      "INFO:tensorflow:loss = 4.5533004, step = 1\n",
      "INFO:tensorflow:global_step/sec: 6.99165\n",
      "INFO:tensorflow:loss = 1.4638567, step = 101 (14.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.15022\n",
      "INFO:tensorflow:loss = 1.1486661, step = 201 (13.987 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.17622\n",
      "INFO:tensorflow:loss = 1.2883472, step = 301 (13.934 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.27774\n",
      "INFO:tensorflow:loss = 1.4515326, step = 401 (13.742 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 500 into E:\\SW_WS\\Python_SW\\face_classification\\src\\models\\emotion_vgg16\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.4249494.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-20-12:38:24\n",
      "INFO:tensorflow:Restoring parameters from E:\\SW_WS\\Python_SW\\face_classification\\src\\models\\emotion_vgg16\\model.ckpt-500\n",
      "INFO:tensorflow:Evaluation [1/100]\n",
      "INFO:tensorflow:Evaluation [2/100]\n",
      "INFO:tensorflow:Evaluation [3/100]\n",
      "INFO:tensorflow:Evaluation [4/100]\n",
      "INFO:tensorflow:Evaluation [5/100]\n",
      "INFO:tensorflow:Evaluation [6/100]\n",
      "INFO:tensorflow:Evaluation [7/100]\n",
      "INFO:tensorflow:Evaluation [8/100]\n",
      "INFO:tensorflow:Evaluation [9/100]\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [11/100]\n",
      "INFO:tensorflow:Evaluation [12/100]\n",
      "INFO:tensorflow:Evaluation [13/100]\n",
      "INFO:tensorflow:Evaluation [14/100]\n",
      "INFO:tensorflow:Evaluation [15/100]\n",
      "INFO:tensorflow:Evaluation [16/100]\n",
      "INFO:tensorflow:Evaluation [17/100]\n",
      "INFO:tensorflow:Evaluation [18/100]\n",
      "INFO:tensorflow:Evaluation [19/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [21/100]\n",
      "INFO:tensorflow:Evaluation [22/100]\n",
      "INFO:tensorflow:Evaluation [23/100]\n",
      "INFO:tensorflow:Evaluation [24/100]\n",
      "INFO:tensorflow:Evaluation [25/100]\n",
      "INFO:tensorflow:Evaluation [26/100]\n",
      "INFO:tensorflow:Evaluation [27/100]\n",
      "INFO:tensorflow:Evaluation [28/100]\n",
      "INFO:tensorflow:Evaluation [29/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [31/100]\n",
      "INFO:tensorflow:Evaluation [32/100]\n",
      "INFO:tensorflow:Evaluation [33/100]\n",
      "INFO:tensorflow:Evaluation [34/100]\n",
      "INFO:tensorflow:Evaluation [35/100]\n",
      "INFO:tensorflow:Evaluation [36/100]\n",
      "INFO:tensorflow:Evaluation [37/100]\n",
      "INFO:tensorflow:Evaluation [38/100]\n",
      "INFO:tensorflow:Evaluation [39/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [41/100]\n",
      "INFO:tensorflow:Evaluation [42/100]\n",
      "INFO:tensorflow:Evaluation [43/100]\n",
      "INFO:tensorflow:Evaluation [44/100]\n",
      "INFO:tensorflow:Evaluation [45/100]\n",
      "INFO:tensorflow:Evaluation [46/100]\n",
      "INFO:tensorflow:Evaluation [47/100]\n",
      "INFO:tensorflow:Evaluation [48/100]\n",
      "INFO:tensorflow:Evaluation [49/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [51/100]\n",
      "INFO:tensorflow:Evaluation [52/100]\n",
      "INFO:tensorflow:Evaluation [53/100]\n",
      "INFO:tensorflow:Evaluation [54/100]\n",
      "INFO:tensorflow:Evaluation [55/100]\n",
      "INFO:tensorflow:Evaluation [56/100]\n",
      "INFO:tensorflow:Evaluation [57/100]\n",
      "INFO:tensorflow:Evaluation [58/100]\n",
      "INFO:tensorflow:Evaluation [59/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [61/100]\n",
      "INFO:tensorflow:Evaluation [62/100]\n",
      "INFO:tensorflow:Evaluation [63/100]\n",
      "INFO:tensorflow:Evaluation [64/100]\n",
      "INFO:tensorflow:Evaluation [65/100]\n",
      "INFO:tensorflow:Evaluation [66/100]\n",
      "INFO:tensorflow:Evaluation [67/100]\n",
      "INFO:tensorflow:Evaluation [68/100]\n",
      "INFO:tensorflow:Evaluation [69/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [71/100]\n",
      "INFO:tensorflow:Evaluation [72/100]\n",
      "INFO:tensorflow:Evaluation [73/100]\n",
      "INFO:tensorflow:Evaluation [74/100]\n",
      "INFO:tensorflow:Evaluation [75/100]\n",
      "INFO:tensorflow:Evaluation [76/100]\n",
      "INFO:tensorflow:Evaluation [77/100]\n",
      "INFO:tensorflow:Evaluation [78/100]\n",
      "INFO:tensorflow:Evaluation [79/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [81/100]\n",
      "INFO:tensorflow:Evaluation [82/100]\n",
      "INFO:tensorflow:Evaluation [83/100]\n",
      "INFO:tensorflow:Evaluation [84/100]\n",
      "INFO:tensorflow:Evaluation [85/100]\n",
      "INFO:tensorflow:Evaluation [86/100]\n",
      "INFO:tensorflow:Evaluation [87/100]\n",
      "INFO:tensorflow:Evaluation [88/100]\n",
      "INFO:tensorflow:Evaluation [89/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [91/100]\n",
      "INFO:tensorflow:Evaluation [92/100]\n",
      "INFO:tensorflow:Evaluation [93/100]\n",
      "INFO:tensorflow:Evaluation [94/100]\n",
      "INFO:tensorflow:Evaluation [95/100]\n",
      "INFO:tensorflow:Evaluation [96/100]\n",
      "INFO:tensorflow:Evaluation [97/100]\n",
      "INFO:tensorflow:Evaluation [98/100]\n",
      "INFO:tensorflow:Evaluation [99/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-20-12:38:30\n",
      "INFO:tensorflow:Saving dict for global step 500: acc = 0.55, global_step = 500, loss = 1.2646544\n",
      "--- 120.07371068000793 seconds ---\n"
     ]
    }
   ],
   "source": [
    "train_spec = tf.estimator.TrainSpec(input_fn=lambda: imgs_input_fn(path_tfrecords_train,\n",
    "                                                                   perform_shuffle=True,\n",
    "                                                                   repeat_count=5,\n",
    "                                                                   batch_size=20), \n",
    "                                    max_steps=500)\n",
    "eval_spec = tf.estimator.EvalSpec(input_fn=lambda: imgs_input_fn(path_tfrecords_test,\n",
    "                                                                 perform_shuffle=False,\n",
    "                                                                 batch_size=1))\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "tf.estimator.train_and_evaluate(est_emotion, train_spec, eval_spec)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict\n",
    "To predict we can set the `labels` to None because that is what we will be predicting.\n",
    "\n",
    "Here we only predict the first 10 images in the test_files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_imgs_input_fn(filenames, batch_size=1):\n",
    "    def _parse_function(filename, label):\n",
    "        image_string = tf.read_file(filename)\n",
    "        image = tf.image.decode_image(image_string, channels=3)\n",
    "        image.set_shape([None, None, None])\n",
    "        image = tf.image.resize_images(image, [224, 224])\n",
    "        image = tf.subtract(image, 116.779) # Zero-center by mean pixel\n",
    "        image.set_shape([224, 224, 3])\n",
    "        image = tf.reverse(image, axis=[2]) # 'RGB'->'BGR'\n",
    "        d = dict(zip([input_name], [image])), label\n",
    "        return d\n",
    "    labels = [0]*len(filenames)\n",
    "    labels=np.array(labels)\n",
    "    # Expand the shape of \"labels\" if necessory\n",
    "    if len(labels.shape) == 1:\n",
    "        labels = np.expand_dims(labels, axis=1)\n",
    "    filenames = tf.constant(filenames)\n",
    "    labels = tf.constant(labels)\n",
    "    labels = tf.cast(labels, tf.float32)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "    dataset = dataset.map(_parse_function)\n",
    "    dataset = dataset.batch(batch_size)  # Batch size to use\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    batch_features, batch_labels = iterator.get_next()\n",
    "    return batch_features, batch_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = [\"./data/small.jpg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_results = est_emotion.predict(\n",
    "    input_fn=lambda: predict_imgs_input_fn(test_files[:1],\n",
    "                                   batch_size=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Input graph does not contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
      "INFO:tensorflow:Restoring parameters from E:\\SW_WS\\Python_SW\\face_classification\\src\\models\\emotion_vgg16\\model.ckpt-500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_logits = []\n",
    "for prediction in predict_results:\n",
    "    predict_logits.append(prediction['dense_2'])\n",
    "predict_logits[0].argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict all validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Input graph does not contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Input graph does not contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from E:\\SW_WS\\Python_SW\\face_classification\\src\\models\\emotion_vgg16\\model.ckpt-500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from E:\\SW_WS\\Python_SW\\face_classification\\src\\models\\emotion_vgg16\\model.ckpt-500\n"
     ]
    }
   ],
   "source": [
    "predict_val_results = est_emotion.predict(\n",
    "    input_fn=lambda: imgs_input_fn(path_tfrecords_test,\n",
    "                                     perform_shuffle=False,\n",
    "                                     batch_size=20))\n",
    "predict_val_logits = []\n",
    "for prediction in predict_val_results:\n",
    "    predict_val_logits.append(prediction['dense_2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the prediction result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = [logits.argmax() for logits in predict_val_logits[:500]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch input shape: (500, 224, 224, 3)\n",
      "batch output shape: (500, 7)\n"
     ]
    }
   ],
   "source": [
    "next_batch = imgs_input_fn(path_tfrecords_test, perform_shuffle=False, batch_size=500)\n",
    "with tf.Session() as sess:\n",
    "    first_batch = sess.run(next_batch)\n",
    "x_d = first_batch[0]['input_1']\n",
    "y_d = first_batch[1]\n",
    "print(\"batch input shape: {}\".format(x_d.shape))\n",
    "print(\"batch output shape: {}\".format(y_d.shape))\n",
    "\n",
    "actual_labels = [logits.argmax() for logits in y_d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.562"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(1 for x,y in zip(actual_labels,predicted_labels) if x == y) / len(actual_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
